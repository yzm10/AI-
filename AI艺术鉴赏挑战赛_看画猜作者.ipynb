{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI艺术鉴赏挑战赛 - 看画猜作者.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPr5UfAdSTOothkQwPLzToY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yzm10/yanxishe/blob/main/AI%E8%89%BA%E6%9C%AF%E9%89%B4%E8%B5%8F%E6%8C%91%E6%88%98%E8%B5%9B_%E7%9C%8B%E7%94%BB%E7%8C%9C%E4%BD%9C%E8%80%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itiFky1V9ziR"
      },
      "source": [
        "# AI研习社 - 艺术鉴赏\n",
        "\n",
        "预训练模型：SE-ResNeXt101_32x4d\n",
        "\n",
        "epoch：8\n",
        "\n",
        "score：61.875\n",
        "\n",
        "~~made by yzm10~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDcy78LEwDDb"
      },
      "source": [
        "导入包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycB3oOOgNrYJ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import time\n",
        "import json\n",
        "\n",
        "\n",
        "# 判断是否存在GPU设备\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VapMzBouwAKH"
      },
      "source": [
        "下载数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8DLO5EmClkN"
      },
      "source": [
        "# ! rm -rf ./train\n",
        "# ! rm -rf ./test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IySKMCDn8mPF"
      },
      "source": [
        "! wget http://qavs3w9z3.bkt.clouddn.com/Art.zip\n",
        "! unzip Art.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRzyaaTrwUKw"
      },
      "source": [
        "读取csv，打标签"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOgtKLpGHELd"
      },
      "source": [
        "import csv\n",
        "csv_file = csv.reader(open('train.csv','r'))\n",
        "\n",
        "AVATAR_STRANGER_PATH=\"./train/\"\n",
        "\n",
        "for name,label in csv_file:\n",
        "  if name=='filename': continue\n",
        "  \n",
        "  image=os.path.join(AVATAR_STRANGER_PATH, name+'.jpg')\n",
        "  print(image)\n",
        "  \n",
        "  # 分离目录和文件名\n",
        "  # dirname, filename = os.path.split(image)\n",
        "  # print(dirname, filename)\n",
        "  \n",
        "  # 改名\n",
        "  new_file=os.path.join(AVATAR_STRANGER_PATH, label+'_'+name+'.jpg')\n",
        "  print(new_file)\n",
        "\n",
        "  os.rename(image, new_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k34VXSPE8_4K"
      },
      "source": [
        "训练集分类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqzgxL6jRkcE"
      },
      "source": [
        "! mkdir ./train/-0_Frida_Kahlo\n",
        "! mkdir ./train/-1_Edgar_Degas\n",
        "! mkdir ./train/-2_Pieter_Bruegel\n",
        "! mkdir ./train/-3_Vincent_van_Gogh\n",
        "! mkdir ./train/-4_Rembrandt\n",
        "! mkdir ./train/-5_Henri_Rousseau\n",
        "! mkdir ./train/-6_Henri_Matisse\n",
        "! mkdir ./train/-7_Joan_Miro\n",
        "! mkdir ./train/-8_Titian\n",
        "! mkdir ./train/-9_Paul_Gauguin\n",
        "! mkdir ./train/10_Pierre-Auguste_Renoir\n",
        "! mkdir ./train/11_Marc_Chagall\n",
        "! mkdir ./train/12_Raphael\n",
        "! mkdir ./train/13_Leonardo_da_Vinci\n",
        "! mkdir ./train/14_Amedeo_Modigliani\n",
        "! mkdir ./train/15_Sandro_Botticelli\n",
        "! mkdir ./train/16_Pablo_Picasso\n",
        "! mkdir ./train/17_Rene_Magritte\n",
        "! mkdir ./train/18_Vasiliy_Kandinskiy\n",
        "! mkdir ./train/19_Salvador_Dali\n",
        "! mkdir ./train/20_Michelangelo\n",
        "! mkdir ./train/21_Mikhail_Vrubel\n",
        "! mkdir ./train/22_Paul_Klee\n",
        "! mkdir ./train/23_Camille_Pissarro\n",
        "! mkdir ./train/24_Giotto_di_Bondone\n",
        "! mkdir ./train/25_Gustave_Courbet\n",
        "! mkdir ./train/26_Gustav_Klimt\n",
        "! mkdir ./train/27_Henri_de_Toulouse-Lautrec\n",
        "! mkdir ./train/28_Francisco_Goya\n",
        "! mkdir ./train/29_Jan_van_Eyck\n",
        "! mkdir ./train/30_Andrei_Rublev\n",
        "! mkdir ./train/31_Andy_Warhol\n",
        "! mkdir ./train/32_Alfred_Sisley\n",
        "! mkdir ./train/33_Paul_Cezanne\n",
        "! mkdir ./train/34_Diego_Velazquez\n",
        "! mkdir ./train/35_Edouard_Manet\n",
        "! mkdir ./train/36_Peter_Paul_Rubens\n",
        "! mkdir ./train/37_Claude_Monet\n",
        "! mkdir ./train/38_Kazimir_Malevich\n",
        "! mkdir ./train/39_Hieronymus_Bosch\n",
        "! mkdir ./train/40_Caravaggio\n",
        "! mkdir ./train/41_Piet_Mondrian\n",
        "! mkdir ./train/42_Diego_Rivera\n",
        "! mkdir ./train/43_El_Greco\n",
        "! mkdir ./train/44_William_Turner\n",
        "! mkdir ./train/45_Georges_Seurat\n",
        "! mkdir ./train/46_Jackson_Pollock\n",
        "! mkdir ./train/47_Edvard_Munch\n",
        "! mkdir ./train/48_Eugene_Delacroix\n",
        "\n",
        "! mkdir ./test/test\n",
        "\n",
        "! mv ./train/0_* ./train/-0_Frida_Kahlo\n",
        "! mv ./train/1_* ./train/-1_Edgar_Degas\n",
        "! mv ./train/2_* ./train/-2_Pieter_Bruegel\n",
        "! mv ./train/3_* ./train/-3_Vincent_van_Gogh\n",
        "! mv ./train/4_* ./train/-4_Rembrandt\n",
        "! mv ./train/5_* ./train/-5_Henri_Rousseau\n",
        "! mv ./train/6_* ./train/-6_Henri_Matisse\n",
        "! mv ./train/7_* ./train/-7_Joan_Miro\n",
        "! mv ./train/8_* ./train/-8_Titian\n",
        "! mv ./train/9_* ./train/-9_Paul_Gauguin\n",
        "! mv ./train/10_* ./train/10_Pierre-Auguste_Renoir\n",
        "! mv ./train/11_* ./train/11_Marc_Chagall\n",
        "! mv ./train/12_* ./train/12_Raphael\n",
        "! mv ./train/13_* ./train/13_Leonardo_da_Vinci\n",
        "! mv ./train/14_* ./train/14_Amedeo_Modigliani\n",
        "! mv ./train/15_* ./train/15_Sandro_Botticelli\n",
        "! mv ./train/16_* ./train/16_Pablo_Picasso\n",
        "! mv ./train/17_* ./train/17_Rene_Magritte\n",
        "! mv ./train/18_* ./train/18_Vasiliy_Kandinskiy\n",
        "! mv ./train/19_* ./train/19_Salvador_Dali\n",
        "! mv ./train/20_* ./train/20_Michelangelo\n",
        "! mv ./train/21_* ./train/21_Mikhail_Vrubel\n",
        "! mv ./train/22_* ./train/22_Paul_Klee\n",
        "! mv ./train/23_* ./train/23_Camille_Pissarro\n",
        "! mv ./train/24_* ./train/24_Giotto_di_Bondone\n",
        "! mv ./train/25_* ./train/25_Gustave_Courbet\n",
        "! mv ./train/26_* ./train/26_Gustav_Klimt\n",
        "! mv ./train/27_* ./train/27_Henri_de_Toulouse-Lautrec\n",
        "! mv ./train/28_* ./train/28_Francisco_Goya\n",
        "! mv ./train/29_* ./train/29_Jan_van_Eyck\n",
        "! mv ./train/30_* ./train/30_Andrei_Rublev\n",
        "! mv ./train/31_* ./train/31_Andy_Warhol\n",
        "! mv ./train/32_* ./train/32_Alfred_Sisley\n",
        "! mv ./train/33_* ./train/33_Paul_Cezanne\n",
        "! mv ./train/34_* ./train/34_Diego_Velazquez\n",
        "! mv ./train/35_* ./train/35_Edouard_Manet\n",
        "! mv ./train/36_* ./train/36_Peter_Paul_Rubens\n",
        "! mv ./train/37_* ./train/37_Claude_Monet\n",
        "! mv ./train/38_* ./train/38_Kazimir_Malevich\n",
        "! mv ./train/39_* ./train/39_Hieronymus_Bosch\n",
        "! mv ./train/40_* ./train/40_Caravaggio\n",
        "! mv ./train/41_* ./train/41_Piet_Mondrian\n",
        "! mv ./train/42_* ./train/42_Diego_Rivera\n",
        "! mv ./train/43_* ./train/43_El_Greco\n",
        "! mv ./train/44_* ./train/44_William_Turner\n",
        "! mv ./train/45_* ./train/45_Georges_Seurat\n",
        "! mv ./train/46_* ./train/46_Jackson_Pollock\n",
        "! mv ./train/47_* ./train/47_Edvard_Munch\n",
        "! mv ./train/48_* ./train/48_Eugene_Delacroix\n",
        "\n",
        "! mv ./test/* ./test/test/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx87q5PKDcK8"
      },
      "source": [
        "数据处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wi-FjZsUuWL"
      },
      "source": [
        "resnet_format = transforms.Compose([\n",
        "  transforms.RandomHorizontalFlip(p=0.5),\n",
        "\n",
        "  transforms.RandomResizedCrop(size=(224, 224), scale=(0.6, 1.0)),\n",
        "  # transforms.Resize((224, 224)),\n",
        "  transforms.ToTensor(), # ->(0,1)\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ->(-1,1)\n",
        "])\n",
        "\n",
        "data_dir = './'\n",
        "\n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), resnet_format)\n",
        "         for x in ['train']}\n",
        "\n",
        "tsets = {y: datasets.ImageFolder(os.path.join(data_dir, y), resnet_format)\n",
        "        for y in ['test']}\n",
        "\n",
        "dset_sizes = {x: len(dsets[x]) for x in ['train']}\n",
        "dset_classes = dsets['train'].classes\n",
        "\n",
        "# 通过下面代码可以查看 dsets 的一些属性\n",
        "\n",
        "print(dsets['train'].classes)\n",
        "print(dsets['train'].class_to_idx)\n",
        "print(dsets['train'].imgs[:5])\n",
        "print('dset_sizes: ', dset_sizes)\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(dsets['train'], batch_size=64, shuffle=True, num_workers=6)\n",
        "\n",
        "loader_test = torch.utils.data.DataLoader(tsets['test'],batch_size=8,shuffle=False,num_workers=6)\n",
        "\n",
        "# 把第一个 batch 保存到 inputs_try, labels_try，分别查看\n",
        "\n",
        "print(labels_try)\n",
        "print(inputs_try.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVTna01qEQAD"
      },
      "source": [
        "# 显示图片的小程序\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "#   Imshow for Tensor.\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = np.clip(std * inp + mean, 0,1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "# 显示 labels_try 的5张图片，即valid里第一个batch的5张图片\n",
        "out = torchvision.utils.make_grid(inputs_try)\n",
        "imshow(out, title=[dset_classes[x] for x in labels_try])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2qYYfZct0wT"
      },
      "source": [
        "建模"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoUuAwkJ6_aF"
      },
      "source": [
        "# se_resnext101_32x4d\n",
        "! pip install pretrainedmodels\n",
        "import pretrainedmodels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLDYFt2ytrh_"
      },
      "source": [
        "model_1 = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, pretrained='imagenet')\n",
        "\n",
        "print('1****************')\n",
        "print(model_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH9OjXnPwmpu"
      },
      "source": [
        "fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TheS4W7wlym"
      },
      "source": [
        "for param in model_1.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "model_1.last_linear = nn.Sequential(\n",
        "    nn.Linear(2048, 49)\n",
        ")\n",
        "\n",
        "model_1 = model_1.to(device)\n",
        "\n",
        "print('1****************')\n",
        "print(model_1.last_linear)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3VvgiauzR2W"
      },
      "source": [
        "训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKcpIQiAzUJU"
      },
      "source": [
        "'''\n",
        "第一步：创建损失函数和优化器\n",
        "\n",
        "损失函数 NLLLoss() 的 输入 是一个对数概率向量和一个目标标签. \n",
        "它不会为我们计算对数概率，适合最后一层是log_softmax()的网络. \n",
        "'''\n",
        "# criterion = nn.NLLLoss()\n",
        "# 二分类：NLLLoss（负对数似然损失函数）\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 多分类：CrossEntropyLoss（交叉熵损失函数）\n",
        "\n",
        "# 学习率 Adam最优3e-4\n",
        "lr = 0.0003\n",
        "\n",
        "# 随机梯度下降\n",
        "# optimizer_vgg = torch.optim.SGD(model_vgg_new.classifier[6].parameters(),lr = lr)\n",
        "# Adam\n",
        "optimizer_1 = torch.optim.Adam(model_1.last_linear.parameters(),lr = lr)\n",
        "\n",
        "def smooth_one_hot(true_labels: torch.Tensor, classes: int, smoothing=0.0):\n",
        "    \"\"\"\n",
        "    if smoothing == 0, it's one-hot method\n",
        "    if 0 < smoothing < 1, it's smooth method\n",
        "\n",
        "    \"\"\"\n",
        "    assert 0 <= smoothing < 1\n",
        "    confidence = 1.0 - smoothing\n",
        "    label_shape = torch.Size((true_labels.size(0), classes))\n",
        "    with torch.no_grad():\n",
        "        true_dist = torch.empty(size=label_shape, device=true_labels.device)\n",
        "        true_dist.fill_(smoothing / (classes - 1))\n",
        "        true_dist.scatter_(1, true_labels.data.unsqueeze(1), confidence)\n",
        "    return true_dist\n",
        "\n",
        "'''\n",
        "第二步：训练模型\n",
        "'''\n",
        "\n",
        "def train_model(model,dataloader,size,epochs=1,optimizer=None):\n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        count = 0\n",
        "        for i, (inputs, classes) in enumerate(dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            classes = classes.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # smooth_label = smooth_one_hot(classes, classes=6, smoothing=0.1)\n",
        "            loss = criterion(outputs, classes)           \n",
        "            \n",
        "            optimizer = optimizer\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if i % 10 == 0:   \n",
        "              print('Epoch: %d Minibatch: %5d loss: %.3f' %(epoch + 1, i + 1, loss.item()))\n",
        "\n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == classes.data)\n",
        "            count += len(inputs)\n",
        "            print('Training: No. ', count, ' process ... total: ', size)\n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.data.item() / size\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                     epoch_loss, epoch_acc))\n",
        "        \n",
        "        \n",
        "# 模型训练\n",
        "print('1****************')\n",
        "train_model(model_1,loader_train,size=dset_sizes['train'], epochs=8, optimizer=optimizer_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptsFT8Mj0y_F"
      },
      "source": [
        "输出结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HlslcYd0yE3"
      },
      "source": [
        "import re\n",
        "\n",
        "def answer(model):\n",
        "  # 得到测试图片编号\n",
        "  string = tsets['test'].imgs[0][0]\n",
        "  num = re.sub(\"\\D\", \"\", string)\n",
        "\n",
        "  result_pro = []\n",
        "  result_pre = []\n",
        "  # 将测试数据集（test）输入到网络中，得到识别结果\n",
        "  for item,lable in loader_test:\n",
        "    item = item.to(device)\n",
        "    ll =  model(item)\n",
        "    pro, pre = torch.max(ll.data,1)\n",
        "\n",
        "    result_pro += pro\n",
        "    result_pre += pre\n",
        "\n",
        "  # 结果排序\n",
        "  result_end =list()\n",
        "\n",
        "  for i in range(800):\n",
        "    string = tsets['test'].imgs[i][0]\n",
        "    num = re.sub(\"\\D\", \"\", string)\n",
        "    result_end.append((num, result_pre[i].item(), result_pro[i].item()))\n",
        "\n",
        "  result_sort = sorted(result_end,key=lambda x:int(x[0]))\n",
        "  return result_sort\n",
        "\n",
        "result_1 = answer(model_1)\n",
        "\n",
        "print('1****************')\n",
        "print(result_1)\n",
        "\n",
        "import csv\n",
        "# 写入文件\n",
        "\n",
        "f = open('out_file.csv','w')\n",
        "writer = csv.writer(f)\n",
        "for id, res, _ in result_1:\n",
        "\n",
        "  ans = id, res\n",
        "  writer.writerow(ans)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}